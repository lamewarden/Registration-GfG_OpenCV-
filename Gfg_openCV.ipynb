{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import block\n",
    "import cv2\n",
    "import numpy as np\n",
    "from pathlib import Path\n",
    "import os\n",
    "import csv"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Homography matrix (2 images)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    " \n",
    "# Open the image files.\n",
    "img1_color = cv2.imread(\"/mnt/buf/PSI/Multispec/2023.04.21_alignment_photo/Original images/1st alignment_ch0.png\")  # Image to be aligned.\n",
    "img2_color = cv2.imread(\"/mnt/buf/PSI/Multispec/2023.04.21_alignment_photo/Original images/1st alignment_ch5.png\")     # Reference image.\n",
    "\n",
    "# Convert to grayscale.\n",
    "img1 = cv2.cvtColor(img1_color, cv2.COLOR_BGR2GRAY)\n",
    "img2 = cv2.cvtColor(img2_color, cv2.COLOR_BGR2GRAY)\n",
    "height, width = img2.shape\n",
    "  \n",
    "# Create ORB detector with 5000 features.\n",
    "orb_detector = cv2.ORB_create(5000)\n",
    "  \n",
    "# Find keypoints and descriptors.\n",
    "# The first arg is the image, second arg is the mask\n",
    "#  (which is not required in this case).\n",
    "kp1, d1 = orb_detector.detectAndCompute(img1, None)\n",
    "kp2, d2 = orb_detector.detectAndCompute(img2, None)\n",
    "  \n",
    "# Match features between the two images.\n",
    "# We create a Brute Force matcher with \n",
    "# Hamming distance as measurement mode.\n",
    "matcher = cv2.BFMatcher(cv2.NORM_HAMMING, crossCheck = True)\n",
    "  \n",
    "# Match the two sets of descriptors.\n",
    "matches = list(matcher.match(d1, d2))\n",
    "  \n",
    "# Sort matches on the basis of their Hamming distance.\n",
    "matches.sort(key = lambda x: x.distance)\n",
    "  \n",
    "# Take the top 90 % matches forward.\n",
    "matches = matches[:int(len(matches)*0.9)]\n",
    "no_of_matches = len(matches)\n",
    "  \n",
    "# Define empty matrices of shape no_of_matches * 2.\n",
    "p1 = np.zeros((no_of_matches, 2))\n",
    "p2 = np.zeros((no_of_matches, 2))\n",
    "  \n",
    "for i in range(len(matches)):\n",
    "  p1[i, :] = kp1[matches[i].queryIdx].pt\n",
    "  p2[i, :] = kp2[matches[i].trainIdx].pt\n",
    "  \n",
    "# Find the homography matrix.\n",
    "homography, mask = cv2.findHomography(p1, p2, cv2.RANSAC)\n",
    "  \n",
    "%%time\n",
    "# Use this matrix to transform the\n",
    "# colored image wrt the reference image.\n",
    "transformed_img = cv2.warpPerspective(img1_color,\n",
    "                    homography, (width, height))\n",
    "  \n",
    "# Save the output.\n",
    "cv2.imwrite('output.png', transformed_img)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## All images in the folder (homography)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def retrieve_images(root_dir=Path('/mnt/buf/PSI/Multispec/Code/Registration(Medium)/FIRE/Images'), template_img=0):\n",
    "\n",
    "    # Get the list of image filenames (I left only those, which apparently represented same eye)\n",
    "    image_filenames = [f for f in os.listdir(root_dir)]\n",
    "    \n",
    "    # Read the images into a list\n",
    "    images = [cv2.imread(str(root_dir / f)) for f in image_filenames]\n",
    "    # Convert the images to grayscale\n",
    "    gray_images = [cv2.cvtColor(img, cv2.COLOR_BGR2GRAY) for img in images]\n",
    "    # Register all images to the first image\n",
    "    template = gray_images[template_img]\n",
    "\n",
    "    height, width = template.shape\n",
    "    \n",
    "    # Create ORB detector with 5000 features.\n",
    "    orb_detector = cv2.ORB_create(5000)\n",
    "    \n",
    "    # Find keypoints and descriptors.\n",
    "    # The first arg is the image, second arg is the mask\n",
    "    #  (which is not required in this case).\n",
    "    kt, dt = orb_detector.detectAndCompute(template, None)\n",
    "    homography_arr = []\n",
    "    for num, image in enumerate(gray_images):\n",
    "        k2, d2 = orb_detector.detectAndCompute(image, None)\n",
    "    \n",
    "        # Match features between the two images.\n",
    "        # We create a Brute Force matcher with \n",
    "        # Hamming distance as measurement mode.\n",
    "        matcher = cv2.BFMatcher(cv2.NORM_HAMMING, crossCheck = True)\n",
    "        \n",
    "        # Match the two sets of descriptors.\n",
    "        matches = list(matcher.match(dt, d2))\n",
    "        \n",
    "        # Sort matches on the basis of their Hamming distance.\n",
    "        matches.sort(key = lambda x: x.distance)\n",
    "        \n",
    "        # Take the top 90 % matches forward.\n",
    "        matches = matches[:int(len(matches)*0.9)]\n",
    "        no_of_matches = len(matches)\n",
    "        \n",
    "        # Define empty matrices of shape no_of_matches * 2.\n",
    "        pt = np.zeros((no_of_matches, 2))\n",
    "        p2 = np.zeros((no_of_matches, 2))\n",
    "        \n",
    "        for i in range(len(matches)):\n",
    "            pt[i, :] = kt[matches[i].queryIdx].pt\n",
    "            p2[i, :] = k2[matches[i].trainIdx].pt\n",
    "        \n",
    "        # Find the homography matrix.\n",
    "        homography, mask = cv2.findHomography(p2, pt, cv2.RANSAC)\n",
    "        homography_arr.append(homography)\n",
    "        # Use this matrix to transform the\n",
    "        # colored image wrt the reference image.\n",
    "        transformed_img = cv2.warpPerspective(images[num],\n",
    "                            homography, (width, height))\n",
    "        \n",
    "        # Save the output.\n",
    "        cv2.imwrite(f'output_channel{num}.png', transformed_img)\n",
    "    # now we save homography_arr as csv file\n",
    "\n",
    "    b = open('homography_matrices.csv', 'w')\n",
    "    a = csv.writer(b)\n",
    "    a.writerows(homography_arr)\n",
    "    b.close()\n",
    "    b\n",
    "    return homography_arr\n",
    "        \n",
    "                \n",
    "            \n",
    "\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Homography matrix decomposition (so far failing)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def decompose_homography(H):\n",
    "    # Extract rotation and translation\n",
    "    R = H[:2, :2]\n",
    "    t = H[:2, 2]\n",
    "    \n",
    "    # Calculate rotation angle in degrees\n",
    "    theta = np.arctan2(R[1, 0], R[0, 0]) * 180 / np.pi\n",
    "    \n",
    "    # Calculate pixel shift in x and y directions\n",
    "    shift_x = t[0]\n",
    "    shift_y = t[1]\n",
    "    # Calculate scaling factor\n",
    "    s = np.linalg.norm(R[:, 0]) + np.linalg.norm(R[:, 1]) / 2\n",
    "    \n",
    "    \n",
    "    return shift_x, shift_y, theta, s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------------Channel 0---------------\n",
      "Pixel shift in x of channel 0 is: 2.26\n",
      "Pixel shift in y of channel 0 is: 1.81\n",
      "Rotation in channel 0 is 0.03 degrees: \n",
      " \n",
      "--------------Channel 1---------------\n",
      "Pixel shift in x of channel 1 is: 6.21\n",
      "Pixel shift in y of channel 1 is: 4.5\n",
      "Rotation in channel 1 is 0.03 degrees: \n",
      " \n",
      "--------------Channel 2---------------\n",
      "Pixel shift in x of channel 2 is: -0.16\n",
      "Pixel shift in y of channel 2 is: -0.16\n",
      "Rotation in channel 2 is 0.01 degrees: \n",
      " \n",
      "--------------Channel 3---------------\n",
      "Pixel shift in x of channel 3 is: -1.99\n",
      "Pixel shift in y of channel 3 is: -0.94\n",
      "Rotation in channel 3 is -0.06 degrees: \n",
      " \n",
      "--------------Channel 4---------------\n",
      "Pixel shift in x of channel 4 is: 0.0\n",
      "Pixel shift in y of channel 4 is: 0.0\n",
      "Rotation in channel 4 is 0.0 degrees: \n",
      " \n",
      "--------------Channel 5---------------\n",
      "Pixel shift in x of channel 5 is: -2.31\n",
      "Pixel shift in y of channel 5 is: -1.14\n",
      "Rotation in channel 5 is -0.04 degrees: \n",
      " \n",
      "CPU times: user 13 s, sys: 405 ms, total: 13.4 s\n",
      "Wall time: 4.33 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "hom_arr = retrieve_images(template_img=4)\n",
    "for num, arr in enumerate(hom_arr):\n",
    "    # Example usage\n",
    "    shift_x, shift_y, theta, s = decompose_homography(arr)\n",
    "    print(f\"--------------Channel {num}---------------\")\n",
    "    print(f\"Pixel shift in x of channel {num} is: {round(shift_x,2)}\")\n",
    "    print(f\"Pixel shift in y of channel {num} is: {round(shift_y, 2)}\")\n",
    "    print(f\"Rotation in channel {num} is {round(theta, 2)} degrees: \")\n",
    "    print(f\" \")\n",
    "    \n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Affine transformation variant\n",
    "(should be a bit faster, but little bit less precise)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Open the image files.\n",
    "img1_color = cv2.imread(\"/mnt/buf/PSI/Multispec/2023.04.21_alignment_photo/Original images/1st alignment_ch0.png\")  # Image to be aligned.\n",
    "img2_color = cv2.imread(\"/mnt/buf/PSI/Multispec/2023.04.21_alignment_photo/Original images/1st alignment_ch5.png\")     # Reference image.\n",
    "\n",
    "# Convert to grayscale.\n",
    "img1 = cv2.cvtColor(img1_color, cv2.COLOR_BGR2GRAY)\n",
    "img2 = cv2.cvtColor(img2_color, cv2.COLOR_BGR2GRAY)\n",
    "height, width = img2.shape\n",
    "\n",
    "# Create ORB detector with 5000 features.\n",
    "orb_detector = cv2.ORB_create(5000)\n",
    "\n",
    "# Find keypoints and descriptors.\n",
    "kp1, d1 = orb_detector.detectAndCompute(img1, None)\n",
    "kp2, d2 = orb_detector.detectAndCompute(img2, None)\n",
    "\n",
    "# Match features between the two images.\n",
    "matcher = cv2.BFMatcher(cv2.NORM_HAMMING, crossCheck=True)\n",
    "matches = list(matcher.match(d1, d2))\n",
    "\n",
    "# Sort matches based on distance.\n",
    "matches.sort(key=lambda x: x.distance)\n",
    "\n",
    "# Take the top 90% matches.\n",
    "matches = matches[:int(len(matches)*0.9)]\n",
    "\n",
    "# Extract matched keypoints.\n",
    "src_pts = np.float32([kp1[m.queryIdx].pt for m in matches]).reshape(-1, 1, 2)\n",
    "dst_pts = np.float32([kp2[m.trainIdx].pt for m in matches]).reshape(-1, 1, 2)\n",
    "\n",
    "# Find affine transform.\n",
    "affine, mask = cv2.estimateAffine2D(src_pts, dst_pts, method=cv2.RANSAC, ransacReprojThreshold=5)\n",
    "\n",
    "# Apply transform to the image.\n",
    "transformed_img = cv2.warpAffine(img1_color, affine, (width, height))\n",
    "\n",
    "# Save the output.\n",
    "cv2.imwrite('Affine_output.png', transformed_img)\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Geometric similar transformation \n",
    "### (affine with 4 DOF - translation (x; y), rotation, scaling)\n",
    "**Less precise, but easy for decomposition**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "  \n",
    "# Open the image files.\n",
    "img1_color = cv2.imread(\"/mnt/buf/PSI/Multispec/2023.04.21_alignment_photo/Original images/1st alignment_ch0.png\")  # Image to be aligned.\n",
    "img2_color = cv2.imread(\"/mnt/buf/PSI/Multispec/2023.04.21_alignment_photo/Original images/1st alignment_ch5.png\")     # Reference image.\n",
    "\n",
    "# Convert to grayscale.\n",
    "img1 = cv2.cvtColor(img1_color, cv2.COLOR_BGR2GRAY)\n",
    "img2 = cv2.cvtColor(img2_color, cv2.COLOR_BGR2GRAY)\n",
    "height, width = img2.shape\n",
    "  \n",
    "# Create ORB detector with 5000 features.\n",
    "orb_detector = cv2.ORB_create(5000)\n",
    "  \n",
    "# Find keypoints and descriptors.\n",
    "# The first arg is the image, second arg is the mask\n",
    "#  (which is not required in this case).\n",
    "kp1, d1 = orb_detector.detectAndCompute(img1, None)\n",
    "kp2, d2 = orb_detector.detectAndCompute(img2, None)\n",
    "  \n",
    "# Match features between the two images.\n",
    "# We create a Brute Force matcher with \n",
    "# Hamming distance as measurement mode.\n",
    "matcher = cv2.BFMatcher(cv2.NORM_HAMMING, crossCheck = True)\n",
    "  \n",
    "# Match the two sets of descriptors.\n",
    "matches = list(matcher.match(d1, d2))\n",
    "  \n",
    "# Sort matches on the basis of their Hamming distance.\n",
    "matches.sort(key = lambda x: x.distance)\n",
    "  \n",
    "# Take the top 90 % matches forward.\n",
    "matches = matches[:int(len(matches)*0.9)]\n",
    "no_of_matches = len(matches)\n",
    "  \n",
    "# Define empty matrices of shape no_of_matches * 2.\n",
    "p1 = np.zeros((no_of_matches, 2))\n",
    "p2 = np.zeros((no_of_matches, 2))\n",
    "  \n",
    "for i in range(len(matches)):\n",
    "  p1[i, :] = kp1[matches[i].queryIdx].pt\n",
    "  p2[i, :] = kp2[matches[i].trainIdx].pt\n",
    "  \n",
    "# Find the affine transformation matrix.\n",
    "affine_transform, mask = cv2.estimateAffinePartial2D(p1, p2, cv2.RANSAC)\n",
    "  \n",
    "# Use this matrix to transform the\n",
    "# colored image wrt the reference image.\n",
    "transformed_img = cv2.warpAffine(img1_color, affine_transform, (width, height))\n",
    "  \n",
    "# Save the output.\n",
    "cv2.imwrite('output.png', transformed_img)\n",
    "cv2.imwrite('img1_orig.png', img1)\n",
    "cv2.imwrite('img2_orig.png', img2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "tn_teta = round(round(affine_transform[1,0], 6)/round(affine_transform[0,0], 6),6)\n",
    "teta_degrees = round(np.arctan(tn_teta)*180/np.pi, 6)\n",
    "scaling = round(affine_transform[0,0]/np.cos(teta_degrees*np.pi/180), 6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pixel shift in x is: 13.59\n",
      "Pixel shift in y is: -3.25\n",
      "Rotation is 0.467 degrees: \n",
      "Scale coeficient is 0.996597\n"
     ]
    }
   ],
   "source": [
    "print(f\"Pixel shift in x is: {round(affine_transform[0,2],2)}\")\n",
    "print(f\"Pixel shift in y is: {round(affine_transform[1,2],2)}\")\n",
    "print(f\"Rotation is {round(teta_degrees, 4)} degrees: \")\n",
    "print(f\"Scale coeficient is {scaling}\")"
   ]
  },
  {
   "attachments": {
    "image.png": {
     "image/png": "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"
    }
   },
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![image.png](attachment:image.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "arctan_teta = np.arctan(tn_teta)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-0.008150826352087"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "arctan_teta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
